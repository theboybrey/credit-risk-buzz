{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Baseline Models Training\n",
    "\n",
    "## Section D: Machine Learning Model Design\n",
    "\n",
    "This notebook implements and compares two scalable machine learning models:\n",
    "1. **Random Forest** - Tree-based ensemble (scalable)\n",
    "2. **XGBoost** - Gradient boosting (state-of-art for tabular data)\n",
    "\n",
    "Both models are:\n",
    "- Unsuitable for small toy datasets (require substantial data)\n",
    "- Scalable through parallel processing\n",
    "- Capable of handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from config import PROCESSED_DATA_DIR, RESULTS_DIR, RANDOM_STATE\n",
    "from src.models import ModelTrainer, train_all_models\n",
    "from src.evaluation import (\n",
    "    compute_metrics, evaluate_at_scales, \n",
    "    plot_roc_curves, plot_precision_recall_curves,\n",
    "    generate_evaluation_report\n",
    ")\n",
    "from src.visualization import (\n",
    "    plot_class_distribution, plot_confusion_matrix,\n",
    "    plot_feature_importance, plot_metrics_comparison,\n",
    "    create_summary_dashboard\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Imports successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "df = pd.read_csv(PROCESSED_DATA_DIR / 'loan_data_processed.csv')\n",
    "\n",
    "print('='*60)\n",
    "print('DATASET OVERVIEW')\n",
    "print('='*60)\n",
    "print(f'Total records: {len(df):,}')\n",
    "print(f'Total features: {len(df.columns)}')\n",
    "print(f'Memory usage: {df.memory_usage(deep=True).sum() / 1e6:.2f} MB')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(df['default'].value_counts())\n",
    "print(f'\\nDefault rate: {df[\"default\"].mean()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Random Forest Classifier\n",
    "\n",
    "### Why Random Forest fits the data characteristics:\n",
    "- **Handles mixed feature types**: Numerical and categorical features\n",
    "- **Robust to outliers**: Tree-based splitting not affected by extreme values\n",
    "- **Feature importance**: Built-in importance scores for interpretability\n",
    "- **Scalable**: Parallelizable with n_jobs=-1\n",
    "- **Handles imbalance**: class_weight='balanced' adjusts for class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ModelTrainer(random_state=RANDOM_STATE)\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(df, target_col='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print('\\n' + '='*60)\n",
    "print('TRAINING RANDOM FOREST')\n",
    "print('='*60)\n",
    "\n",
    "rf_model, rf_results = trainer.train_model(\n",
    "    'RandomForest', \n",
    "    X_train, y_train, \n",
    "    X_test, y_test,\n",
    "    tune_hyperparameters=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "rf_importance = trainer.get_feature_importance('RandomForest')\n",
    "print('\\nTop 15 Most Important Features (Random Forest):')\n",
    "print(rf_importance.head(15).to_string(index=False))\n",
    "\n",
    "fig = plot_feature_importance(rf_importance, top_n=15, \n",
    "                              title='Random Forest Feature Importance')\n",
    "plt.savefig(RESULTS_DIR / 'rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost Classifier\n",
    "\n",
    "### Why XGBoost fits the data characteristics:\n",
    "- **State-of-the-art for tabular data**: Consistently wins competitions\n",
    "- **Handles imbalance**: scale_pos_weight parameter\n",
    "- **Regularization**: L1/L2 regularization prevents overfitting\n",
    "- **Scalable**: tree_method='hist' for faster training on large datasets\n",
    "- **Missing value handling**: Built-in handling of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print('\\n' + '='*60)\n",
    "print('TRAINING XGBOOST')\n",
    "print('='*60)\n",
    "\n",
    "imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f'\\nImbalance ratio: {imbalance_ratio:.2f}')\n",
    "\n",
    "xgb_model, xgb_results = trainer.train_model(\n",
    "    'XGBoost', \n",
    "    X_train, y_train, \n",
    "    X_test, y_test,\n",
    "    tune_hyperparameters=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Feature Importance\n",
    "xgb_importance = trainer.get_feature_importance('XGBoost')\n",
    "print('\\nTop 15 Most Important Features (XGBoost):')\n",
    "print(xgb_importance.head(15).to_string(index=False))\n",
    "\n",
    "fig = plot_feature_importance(xgb_importance, top_n=15, \n",
    "                              title='XGBoost Feature Importance')\n",
    "plt.savefig(RESULTS_DIR / 'xgb_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('MODEL COMPARISON')\n",
    "print('='*60)\n",
    "\n",
    "comparison_df = trainer.compare_models()\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig = plot_roc_curves(trainer.models, X_test, y_test,\n",
    "                      save_path=RESULTS_DIR / 'roc_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, model) in zip(axes, trainer.models.items()):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Non-Default', 'Default'],\n",
    "                yticklabels=['Non-Default', 'Default'])\n",
    "    ax.set_title(f'{name} Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('COMPUTATIONAL COST ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "print(f'\\nTraining Data Size: {len(X_train):,} samples x {X_train.shape[1]} features')\n",
    "print(f'Test Data Size: {len(X_test):,} samples')\n",
    "\n",
    "for model_name, results in trainer.results.items():\n",
    "    train_time = results['training_time']\n",
    "    throughput = len(X_train) / train_time\n",
    "    print(f'{model_name}: {train_time:.2f}s ({throughput:,.0f} samples/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "comparison_df.to_csv(RESULTS_DIR / 'model_comparison.csv', index=False)\n",
    "rf_importance.to_csv(RESULTS_DIR / 'rf_feature_importance.csv', index=False)\n",
    "xgb_importance.to_csv(RESULTS_DIR / 'xgb_feature_importance.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "for name, model in trainer.models.items():\n",
    "    joblib.dump(model, RESULTS_DIR / f'{name.lower()}_model.joblib')\n",
    "\n",
    "print('Results and models saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
